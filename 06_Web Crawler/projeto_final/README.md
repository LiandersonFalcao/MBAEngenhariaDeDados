# Projeto de Pipelines ETL - News Feed e Market Data

Este projeto implementa pipelines ETL (Extract, Transform, Load) para coleta e processamento de dados de notÃ­cias financeiras e dados de mercado, utilizando uma arquitetura modular e interfaces bem definidas.

## ğŸ“‹ VisÃ£o Geral

O projeto Ã© composto por dois pipelines principais:

### ğŸ” News Feed Pipeline
- **Fonte**: InfoMoney (web scraping com Selenium)
- **FunÃ§Ã£o**: Coleta notÃ­cias financeiras em tempo real
- **Tecnologias**: Selenium WebDriver, BeautifulSoup
- **Armazenamento**: DuckDB

### ğŸ“Š Market Data Pipeline  
- **Fonte**: Yahoo Finance API (YFinance)
- **FunÃ§Ã£o**: Coleta dados histÃ³ricos de ativos financeiros
- **Tecnologias**: YFinance, Pandas
- **Armazenamento**: DuckDB

## ğŸ—ï¸ Arquitetura

### Estrutura de DiretÃ³rios
```
my_project/
â”œâ”€â”€ bases/                    # Classes base e interfaces
â”‚   â”œâ”€â”€ crawlers/            # Crawlers base
â”‚   â””â”€â”€ interfaces/          # Interfaces ETL
â”œâ”€â”€ config/                  # ConfiguraÃ§Ãµes
â”‚   â”œâ”€â”€ logging.py          # Setup de logging
â”‚   â””â”€â”€ settings.py         # ConfiguraÃ§Ãµes gerais
â”œâ”€â”€ news_feed/              # Pipeline de notÃ­cias
â”‚   â”œâ”€â”€ crawler_info_money.py
â”‚   â”œâ”€â”€ extractor.py
â”‚   â”œâ”€â”€ transformer.py
â”‚   â”œâ”€â”€ loader.py
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ market_data/            # Pipeline de dados de mercado
â”‚   â”œâ”€â”€ extractor.py
â”‚   â”œâ”€â”€ transformer.py
â”‚   â”œâ”€â”€ loader.py
â”‚   â””â”€â”€ pipeline.py
â”œâ”€â”€ data/                   # Banco de dados
â”‚   â””â”€â”€ dck.db
â”œâ”€â”€ logs/                   # Logs do sistema
â”‚   â””â”€â”€ pipeline.log
â””â”€â”€ main.py                 # Ponto de entrada
```

### PadrÃ£o ETL Implementado

Cada pipeline segue o padrÃ£o ETL com interfaces bem definidas:

1. **Extract** (`ExtractInterface`): ExtraÃ§Ã£o de dados das fontes
2. **Transform** (`TransformInterface`): TransformaÃ§Ã£o e limpeza dos dados
3. **Load** (`LoadInterface`): Carregamento no banco de dados

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- Google Chrome (para web scraping)
- ChromeDriver (gerenciado automaticamente pelo Selenium)

### InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**:
```bash
git clone <repository-url>
cd my_project
```

2. **Crie um ambiente virtual**:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

3. **Instale as dependÃªncias**:
```bash
pip install -r requirements.txt
```

## ğŸ“– Como Usar

### ExecuÃ§Ã£o Completa
Para executar ambos os pipelines sequencialmente:

```bash
python main.py
```

### ExecuÃ§Ã£o Individual

#### Pipeline de News Feed
```python
from news_feed.pipeline import NewsFeedPipeline

pipeline = NewsFeedPipeline()
pipeline.execute()
```

#### Pipeline de Market Data
```python
from market_data.pipeline import MarketDataPipeline

pipeline = MarketDataPipeline()
pipeline.execute()
```

### ConfiguraÃ§Ãµes Personalizadas

#### Market Data Pipeline
```python
# Configurar sÃ­mbolo e intervalo
pipeline = MarketDataPipeline(
    symbol="AAPL",  # Apple Inc.
    interval="1h"   # Dados por hora
)
pipeline.execute()
```

## ğŸ”§ ConfiguraÃ§Ãµes

### Logging
O sistema de logging estÃ¡ configurado em `config/logging.py`:
- Logs salvos em `logs/pipeline.log`
- Output tambÃ©m no console
- NÃ­vel de log: INFO

### Banco de Dados
- **Tipo**: DuckDB
- **LocalizaÃ§Ã£o**: `data/dck.db`
- **CriaÃ§Ã£o**: AutomÃ¡tica na primeira execuÃ§Ã£o

## ğŸ“Š Dados Coletados

### News Feed
- TÃ­tulo da notÃ­cia
- URL da notÃ­cia
- Data de publicaÃ§Ã£o
- Categoria/tipo
- ConteÃºdo resumido

### Market Data
- Dados histÃ³ricos OHLCV (Open, High, Low, Close, Volume)
- PerÃ­odo configurÃ¡vel (padrÃ£o: Ãºltimos 6 meses)
- Intervalos: 1d, 1h, 5m, etc.

## ğŸ› ï¸ Desenvolvimento

### Adicionando Novos Extratores
1. Implemente a interface `ExtractInterface`
2. Crie a classe de extraÃ§Ã£o
3. Integre ao pipeline correspondente

### Adicionando Novos Transformadores
1. Implemente a interface `TransformInterface`
2. Defina a lÃ³gica de transformaÃ§Ã£o
3. Integre ao pipeline

### Adicionando Novos Loaders
1. Implemente a interface `LoadInterface`
2. Configure a conexÃ£o com o destino
3. Integre ao pipeline

## ğŸ“ Logs e Monitoramento

- **Arquivo de log**: `logs/pipeline.log`
- **Formato**: `timestamp [level] [module]: message`
- **NÃ­veis**: INFO, WARNING, ERROR, DEBUG

## ğŸ” Troubleshooting

### Problemas Comuns

1. **ChromeDriver nÃ£o encontrado**:
   - O Selenium gerencia automaticamente o ChromeDriver
   - Certifique-se de ter o Google Chrome instalado

2. **Erro de conexÃ£o com YFinance**:
   - Verifique sua conexÃ£o com a internet
   - Alguns sÃ­mbolos podem nÃ£o estar disponÃ­veis

3. **Erro de permissÃ£o no banco**:
   - Verifique se o diretÃ³rio `data/` existe
   - Verifique permissÃµes de escrita

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ‘¥ Autores

- **Lianderson** - *Desenvolvimento inicial* - [@lianderson]

## ğŸ™ Agradecimentos

- InfoMoney pela disponibilizaÃ§Ã£o das notÃ­cias
- Yahoo Finance pela API de dados financeiros
- Comunidade Python pelos pacotes utilizados
